{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Lets create a neural network:\n",
    "\n",
    "> 4 inputs, connected to 3 neurons in a layer.\n",
    "\n",
    "* ***neuron1*** is the summation of the inputs * the weights, with bias1 added\n",
    "\n",
    "* ***neuron2*** is the summation of the inputs * the weights, with bias2 added\n",
    "\n",
    "* ***neuron3*** is the summation of the inputs * the weights, with bias3 added\n",
    "\n",
    "> this is a ***fully connected network***    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.8, 1.21, 2.385]\n"
     ]
    }
   ],
   "source": [
    "inputs = [1, 2, 3, 2.5]\n",
    "\n",
    "weights1 = [0.2, 0.8, -0.5, 1]\n",
    "weights2 = [0.5, -0.91, 0.26, -0.5]\n",
    "weights3 = [-0.26, -0.27, 0.17, 0.87]\n",
    "\n",
    "bias1 = 2\n",
    "bias2 = 3\n",
    "bias3 = 0.5\n",
    "\n",
    "outputs = [\n",
    "    #neuron1 = inputs * weights\n",
    "    inputs[0] * weights1[0] + inputs[1] * weights1[1] + inputs[2] * weights1[2] + inputs[3] * weights1[3] + bias1,\n",
    "    \n",
    "    #neuron2 = inputs * weights\n",
    "    inputs[0] * weights2[0] + inputs[1] * weights2[1] + inputs[2] * weights2[2] + inputs[3] * weights2[3] + bias2,\n",
    "\n",
    "    #neuron3 = inputs * weights\n",
    "    inputs[0] * weights3[0] + inputs[1] * weights3[1] + inputs[2] * weights3[2] + inputs[3] * weights3[3] + bias3,\n",
    "]\n",
    "\n",
    "print(outputs)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lets simplify this code to be more readable and handle dynamically-sized inputs and layers:\n",
    "\n",
    "> this uses a for loop to interate through the weights and biases for each of the neuron\n",
    "\n",
    "* within that for loop, it uses another loop to iterate through the inputs and the corresponding weights for each neuron\n",
    "\n",
    "> it calculates the output for each neuron by doing sum(inputs[i] * weights[i]) + bias, appending to output layer list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2, 0.8, -0.5, 1] 2\n",
      "[0.5, -0.91, 0.26, -0.5] 3\n",
      "[-0.26, -0.27, 0.17, 0.87] 0.5\n",
      "Outputs:  [4.8, 1.21, 2.385]\n"
     ]
    }
   ],
   "source": [
    "inputs = [1, 2, 3, 2.5]\n",
    "\n",
    "weights = [\n",
    "    [0.2, 0.8, -0.5, 1],\n",
    "    [0.5, -0.91, 0.26, -0.5],\n",
    "    [-0.26, -0.27, 0.17, 0.87],\n",
    "]\n",
    "\n",
    "biases = [2, 3, 0.5]\n",
    "\n",
    "#output of the current layer:\n",
    "layer_outputs = []\n",
    "\n",
    "for neuron_weights, neuron_bias in zip(weights, biases):\n",
    "    print(neuron_weights, neuron_bias)\n",
    "    #zeroed output of given neuron\n",
    "    neuron_output =  0\n",
    "    #for each input and weight to the neuron\n",
    "    for n_input, weight in zip(inputs, neuron_weights):\n",
    "        #multiply this input by the associated weight, add bias, add to the neuron's output variable\n",
    "        neuron_output += n_input*weight\n",
    "    # add bias to this neuron output\n",
    "    neuron_output += neuron_bias    \n",
    "    #put neuron's result to the layer's output list\n",
    "    layer_outputs.append(neuron_output)\n",
    "\n",
    "print('Outputs: ', layer_outputs)        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensors, Arrays, and Vectors\n",
    "\n",
    "> What are ***tensors***?\n",
    "\n",
    "* A tensor, fundamentally, is an object that can be represented as an array\n",
    "\n",
    "> So what are ***arrays***?\n",
    "\n",
    "* An array is an ordered, homologous container for numbers. Can be multi-dimensional.\n",
    "\n",
    "    this represents a 2D array, of shape (3, 2), as it contains 3 rows of 2 columns:\n",
    "\n",
    "            list_matrix_array = [\n",
    "                [3, 2],\n",
    "                [5, 1],\n",
    "                [8, 2]]\n",
    "\n",
    "    this represents a 3-dimensional array, with 3rd level of brackets:\n",
    "\n",
    "            lolol = [[[1,5,6,2],\n",
    "                    [3,2,1,3]],\n",
    "                    [[5,2,1,2],\n",
    "                    [6,4,8,4]],\n",
    "                    [[2,8,5,3],\n",
    "                    [1,1,9,4]]]\n",
    "\n",
    "    the first level of the array contains 3 matrices, thus size at this level is of dimension 3.\n",
    "\n",
    "        [[1,5,6,2], [3,2,1,3]]\n",
    "        [[5,2,1,2], [6,4,8,4]]\n",
    "        [[2,8,5,3], [1,1,9,4]]\n",
    "\n",
    "    in the first matrix, it contains 2 lists, thus size at this level is of dimension 2.\n",
    "\n",
    "        [1,5,6,2] and [3,2,1,3]\n",
    "\n",
    "    within the first matrix's list, aformentioned list contains 4 elements, thus size at this level is of dimension 4.    \n",
    "\n",
    "        len([1,5,6,2]) = 4\n",
    "\n",
    "    so the shape of this 3D array is (3, 2, 4)\n",
    "\n",
    "    A ***vector*** is simply a 1-dimensional array, (list is python).     \n",
    "        \n",
    "        vector = [1,2,3]\n",
    "\n",
    "    A 2d array which consists of 1 row of X columns:\n",
    "\n",
    "        2d_array = [[1,2,3]] \n",
    "\n",
    "    The shape of *vector* is (3,), which means that it is a vector (1d array) of 3 elements. On the other hand, 2d_array has a shape of (1, 3), which means that it is a matrix that consists of 2 row and 3 columns (elements)\n",
    "\n",
    "    The difference between the two is that since vector is simply a vector (list), it does not have any row and columms (no orientation), which means that it can be represented as a row or column vector (no transposing necessary). 2d_array is a matrix, so it can be indexed by rows and columns.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dot Product and Vector Addition\n",
    "\n",
    " a ***Dot Product*** is multiplying each element in our inputs and weight vectors element-wise. (Matrix multiplication)\n",
    "\n",
    "* this is a cleaner way to perform the necessary calculations.\n",
    "\n",
    "* the result of the dot product is a scalar value.\n",
    "\n",
    "\n",
    "$ a \\cdot b = \\sum_{i=1}^{n}(a_ib_i) = a_1b_1 + a_2b_2 +...+ a_nB_n $\n",
    " * this represents the sum of products of consecxutive vector elements.\n",
    "\n",
    " > The dot product only works when : same number of columns of first matrix and same number of rows in the second matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "a = [1,2,3]\n",
    "b = [2,3,4]\n",
    "\n",
    "#to obtain the dot product:\n",
    "dot_product = a[0]*b[0] + a[1]*b[1] + a[2]*b[2]\n",
    "print(dot_product)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " the above code is prepresented in mathemetical form as:\n",
    "\n",
    "$ a \\cdot b = [1,2,3] * [2,3,4] = 1 * 2 + 2 * 3 + 3 * 4 = 20 $"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Vector Addition*** is the combination of two two or more vectors to create a new vector\n",
    "\n",
    "* operation is performed element-wise.\n",
    "\n",
    "$ A + B = [A_1 + B_1, A_2 + B_2, ..., A_n + B_n] $\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single Neuron with Numpy\n",
    "\n",
    "Lets code the neuron using the dot product and the addition of vectors in numpy now:\n",
    "\n",
    "* makes the code much simpler to read."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.8]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "inputs = [1.0, 2.0, 3.0, 2.5]\n",
    "weights = [0.2, 0.8, -0.5, 1.0]\n",
    "bias = [2.0]\n",
    "\n",
    "outputs = np.dot(weights, inputs) + bias\n",
    "print(outputs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets now create the code for a network with a layer of three neuron, like the example in the previous code.\n",
    "\n",
    "* for np.dot, it multiplies each of the list of weights with the inputs respectively, so that np.dot can be expanded to:\n",
    "\n",
    "        np.dot(weights, inputs) = [np.dot(weights[0], inputs), np,dot(weights[1], inputs), np.dot(weights[2], inputs)\n",
    "\n",
    "* whatever comes first in np.dot will decide the output shape. In this case, we are passing a list of neuron weights first, then the inputs, as our goal is to get the list of neuron outputs.        \n",
    "\n",
    "* the dot product of a matrix and a vector always results as a list of dot products\n",
    "\n",
    "        A = [[a11,a12,a13],\n",
    "        [a21,a22,a23],\n",
    "        [a31,a32,a33]]\n",
    "        \n",
    "        x = [x1,x2,x3]\n",
    "\n",
    "        A.x = [np.dot(A[0], x), np.dot(A[1], x), np.dot(A[2], x)]        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([4.8  , 1.21 , 2.385])]\n"
     ]
    }
   ],
   "source": [
    "inputs = [1.0, 2.0, 3.0, 2.5]\n",
    "weights = [[0.2, 0.8, -0.5, 1.0], [0.5, -0.91, 0.26, -0.5], [-0.26, -0.27, 0.17, 0.87]]\n",
    "biases = [2.0, 3.0, 0.5]\n",
    "\n",
    "layer_outputs = [np.dot(weights, inputs) + biases]\n",
    "\n",
    "print(layer_outputs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Batch of Data\n",
    "\n",
    "To train, neural networks ten to receive data in ***batches***\n",
    "\n",
    "> it is faster to train in batches in parallel processing, and it helps with the generalization during training.\n",
    "\n",
    "* if you fit one one sample at a time, you are more than likely fitting to that individual sample rather than the whole dataset.\n",
    "\n",
    "* each element in the batch is the ***sample***, also referred to as the ***feature set of instances*** or ***observations***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example of a batch of data:\n",
    "batch = [[1,5,6,2],[3,2,1,3],[5,2,1,2],[6,4,8,4]] #shape: (4,4),"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix Product\n",
    "\n",
    "the ***Matrix Product*** is an operation in which you have two matrices, and you are performing the dot product of all the combinations of rows from the first matrix and the columns of the second matrix, resulting in the dot product matrix of the two original matrices.\n",
    "\n",
    "To perform a matrix product:\n",
    "\n",
    "* size of the second dimension of the left matrix must match the size of the first dimension of the right matrix:\n",
    "\n",
    "    > left matrix: shape = (5,4), right matrix: shape = (4,7), thus the left matrix's column matches the right matrix's row, thus dot product can occur.    \n",
    "\n",
    "    > resultant matrix: (first dimension of first matrix, second dimension of second matrix): shape = (5, 7)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transposition for the Matrix Product\n",
    "\n",
    "recall, a dot product of two vectors equates to the matrix product of a row vector and column vector.\n",
    "\n",
    "***Transposition*** modifies a matrix in a way that its rows becomes its columns and its columns become its rows.\n",
    "\n",
    "$ a * b = a * b^{T} $, where $ b^{T} $ is the Transposition of b.\n",
    "\n",
    "$ \\begin{bmatrix} a & b & c \\end{bmatrix}^{T} = \\begin{bmatrix} a \\\\ b \\\\ c \\end{bmatrix}  $\n",
    "\n",
    "> a n X m matrix becomes a m X n matrix.\n",
    "\n",
    "$ \\begin{bmatrix} 1 & 2 & 3 \\end{bmatrix} * \\begin{bmatrix} 2 \\\\ 3 \\\\ 4 \\end{bmatrix} = [20] $\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#this is a vector (1 dimensional array)\n",
    "np.array([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3]] (1, 3)\n"
     ]
    }
   ],
   "source": [
    "#this is a two-dimensional array (row vector), shape is (1, 3)\n",
    "a = [1,2,3]\n",
    "a = np.expand_dims(np.array(a), axis=0)\n",
    "print(a, a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 3 4]] (1, 3)\n",
      "[[2]\n",
      " [3]\n",
      " [4]] (3, 1)\n"
     ]
    }
   ],
   "source": [
    "#this is a two-dimensional array (column vector), shape is (3, 1)\n",
    "b = [2,3,4]\n",
    "b = np.array([b])\n",
    "print(b, b.shape)\n",
    "b = b.T\n",
    "print(b, b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[20]] (1, 1)\n"
     ]
    }
   ],
   "source": [
    "#lets now perform the dot product of the two (matrix product since both a and b are now 2 dimensional arrays)\n",
    "c = np.dot(a, b)\n",
    "print(c, c.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Layer of Neurons & Batch of Data w/ NumPy\n",
    "\n",
    "As seen previously, we were able to perform the dot product on the inputs and the weights without a transposition because the weights were a matrix, but the inputs were only a vector (n, ). In this case, the dot product results in a vector of dot products performed on each row from the matrix and this single vector.\n",
    "\n",
    "When inputs become a batch of inputs (matrix), we must perform matrix product, which takes all the combinations of rows from the first matrix and columns from the right matrix, perfroming the dot product on them and placing the results in an output array.\n",
    "\n",
    "$\n",
    "     \\begin{bmatrix}\n",
    "         0 & 1\\\\ \n",
    "         0 & 0 \n",
    "     \\end{bmatrix}\n",
    "     \\times\n",
    "     \\begin{bmatrix}\n",
    "         0 & 0\\\\ \n",
    "         1 & 0  \n",
    "     \\end{bmatrix}\n",
    "      =\n",
    "     \\begin{bmatrix}\n",
    "         1 & 0\\\\ \n",
    "         0 & 0   \n",
    "     \\end{bmatrix}\n",
    "  $\n",
    "\n",
    "  Remember, to perform the matrix product, **second dimension from first matrix must match the first dimension of the second matrix!**\n",
    "\n",
    "if a = (3, 4), b = (3, 4), you cannot perform the matrix product of this!\n",
    "\n",
    "transpose b so that b = (4, 3),\n",
    "\n",
    "then, \n",
    "\n",
    "(3, 4) * (4, 3) = (3, 3) matrix!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs shape: (3, 4) weights shape: (3, 4) \n",
      "\n",
      "outputs: \n",
      " [[ 4.8    1.21   2.385]\n",
      " [ 8.9   -1.81   0.2  ]\n",
      " [ 1.41   1.051  0.026]] \n",
      "outputs shape: (3, 3)\n"
     ]
    }
   ],
   "source": [
    "inputs = [[1.0, 2.0, 3.0, 2.5],\n",
    "          [2.0, 5.0, -1.0, 2.0],\n",
    "          [-1.5, 2.7, 3.3, -0.8]\n",
    "         ]\n",
    "\n",
    "weights = [[0.2, 0.8, -0.5, 1.0],\n",
    "           [0.5, -0.91, 0.26, -0.5],\n",
    "           [-0.26, -0.27, 0.17, 0.87]\n",
    "          ]\n",
    "\n",
    "biases = [2.0, 3.0, 0.5]\n",
    "\n",
    "#lets change both of these 2 dimensional lists into numpy arrays,\n",
    "inputs = np.array(inputs)\n",
    "weights = np.array(weights)\n",
    "\n",
    "#lets show the shape of both: (3, 4) matrices,\n",
    "print('inputs shape:', inputs.shape, 'weights shape:', weights.shape, '\\n')\n",
    "\n",
    "#finally, lets do the matrix product of the inputs and the weights. Remember that one of the matrices has \n",
    "#to eb transposed so that the matrix product can be computed correctly.\n",
    "outputs = np.dot(inputs, weights.T) + biases\n",
    "\n",
    "print('outputs: \\n', outputs, '\\noutputs shape:', outputs.shape)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "unlike the code previously where weights were the first parameter in np.dot(), this time inputs is the frist parameter. This is because the resultant array is sample based and not neuron based. the next layer would expect a batch of inputs and the dot product operation will provide a list of layer outputs per each sample.\n",
    "\n",
    "*the dot product of each sampel (row) in the inputs array is calculated with the same set of weights. The reuslt in a list of outputs, one for each sample, that represents the output of the layer for each sample.\n",
    "\n",
    "the biases vector will be added to each row vector of the matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.8]\n"
     ]
    }
   ],
   "source": [
    "x = [(1.0*0.2) + (2.0*0.8) + (3.0*-0.5) + (2.5*1.0)]\n",
    "print(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_m1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0eb7a405789a2ad0bd2595b62391548e17e9d0e8722ef2b8a9281ed387d58286"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
